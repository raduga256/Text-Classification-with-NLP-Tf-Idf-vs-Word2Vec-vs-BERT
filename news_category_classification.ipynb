{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_category_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXE5tZyNdxqWD99oVbBi2s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raduga256/Text-Classification-with-NLP-Tf-Idf-vs-Word2Vec-vs-BERT/blob/main/news_category_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5XbdRAMYm1v"
      },
      "source": [
        "## New Category Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnbkJ6D6lZxB"
      },
      "source": [
        "There are different techniques to extract information from raw text data and use it to train a classification model. This tutorial compares the old school approach of Bag-of-Words (used with a simple machine learning algorithm), the popular Word Embedding model (used with a deep learning neural network), and the state of the art Language models (used with transfer learning from attention-based transformers) that have completely revolutionized the NLP landscape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzN3kJOrPLt"
      },
      "source": [
        "This article yourself first appearance paper of LIME in certain seminars \"Why Should I Trust You?\": Explaining the Predictions of Any Classifierare based on a slide that was announced.\n",
        "https://irisu-inwl.github.io/reveal/lime\n",
        "\n",
        "However, because this slide there is a feeling that was made for those who do not know the machine learning, it was summarized as anew article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVl6f51QrB1i",
        "outputId": "a7d10998-a2b6-4028-ae06-da562676f581"
      },
      "source": [
        "!pip install lime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 34.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 29.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 30.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 32.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 21.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 22.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 20.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 20.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 20.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp37-none-any.whl size=283846 sha256=b9d5e91993612107b4ef8fd7a0549d8265318131da74508206eea14096f0fd52\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c4utRfJrzko",
        "outputId": "a282cdbc-1f76-4e1e-f303-3e54422e783d"
      },
      "source": [
        " # Installing the Tranformers Library\n",
        " !pip -qq install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 47.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vxwCPYfYe0g"
      },
      "source": [
        "# First of all, I need to import the following libraries:\n",
        "\n",
        "## for data\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## for plotting\n",
        "import matplotlib.pyplot\n",
        "import seaborn as sns\n",
        "\n",
        "## for processing\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "## for bag-of-words\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
        "\n",
        "## for explainer\n",
        "from lime import lime_text\n",
        "\n",
        "## for word embedding\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api\n",
        "\n",
        "## for deep learning\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "## for bert language model\n",
        "import transformers\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byOH5US-sZaA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}